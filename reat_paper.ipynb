{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"reat_paper.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOcp5Jwb8k6ISqyUx1fhbQH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3ylNmr8UnwLW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594835206011,"user_tz":300,"elapsed":678,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}},"outputId":"8a4b6ac1-debf-439e-baa6-8044014eb688"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":185,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A9ASjx8yoJSS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":586},"executionInfo":{"status":"ok","timestamp":1594835206310,"user_tz":300,"elapsed":967,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}},"outputId":"5d16b8eb-7969-499e-e0f2-dcd1ed62afd7"},"source":["from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"],"execution_count":186,"outputs":[{"output_type":"stream","text":["[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 11657633032872606217\n",", name: \"/device:XLA_CPU:0\"\n","device_type: \"XLA_CPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 2222702196167190185\n","physical_device_desc: \"device: XLA_CPU device\"\n",", name: \"/device:XLA_GPU:0\"\n","device_type: \"XLA_GPU\"\n","memory_limit: 17179869184\n","locality {\n","}\n","incarnation: 17591022615627754009\n","physical_device_desc: \"device: XLA_GPU device\"\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 15701463552\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 18394245058491585002\n","physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n","]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gpBMTABdoWcs","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594835206311,"user_tz":300,"elapsed":960,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}}},"source":["import torch\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","\n","class BiGRUSentiment(nn.Module):\n","\n","    def __init__(self, embedding_dim, hidden_dim, vocab_size, label_size, use_gpu, batch_size, dropout=0.5):\n","        super(BiGRUSentiment, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.use_gpu = use_gpu\n","        self.batch_size = batch_size\n","        self.dropout = dropout\n","        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n","        self.gru = nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim, bidirectional=True)\n","        self.hidden2label = nn.Linear(hidden_dim*2, label_size)\n","        self.hidden = self.init_hidden()\n","\n","    def init_hidden(self):\n","        # first is the hidden h\n","        # second is the cell c\n","        if self.use_gpu:\n","            return (Variable(torch.zeros(2, self.batch_size, self.hidden_dim).cuda()))\n","        else:\n","            return (Variable(torch.zeros(2, self.batch_size, self.hidden_dim)))\n","\n","    def forward(self, sentence):\n","        x = self.embeddings(sentence).view(len(sentence), self.batch_size, -1)\n","        gru_out, self.hidden = self.gru(x, self.hidden)\n","        y = self.hidden2label(torch.cat((gru_out[-1,:,:150], gru_out[0,:,150:]), 1))\n","        return y, gru_out, x\n","        #log_probs = F.log_softmax(y)\n","        #return log_probs"],"execution_count":187,"outputs":[]},{"cell_type":"code","metadata":{"id":"MBsGb8SsodKa","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594835206314,"user_tz":300,"elapsed":958,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}}},"source":["class GRUSentiment(nn.Module):\n","\n","    def __init__(self, embedding_dim, hidden_dim, vocab_size, label_size, use_gpu, batch_size, dropout=0.7):\n","        super(GRUSentiment, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.use_gpu = use_gpu\n","        self.batch_size = batch_size\n","        self.dropout = dropout\n","        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n","        self.gru = nn.GRU(input_size=embedding_dim, hidden_size=hidden_dim)\n","        self.hidden2label = nn.Linear(hidden_dim, label_size)\n","        self.hidden = self.init_hidden()\n","\n","    def init_hidden(self):\n","        # first is the hidden h\n","        # second is the cell c\n","        if self.use_gpu:\n","            return (Variable(torch.zeros(1, self.batch_size, self.hidden_dim).cuda()))\n","        else:\n","            return (Variable(torch.zeros(1, self.batch_size, self.hidden_dim)))\n","\n","    def forward(self, sentence):\n","        x = self.embeddings(sentence).view(len(sentence), self.batch_size, -1)\n","        gru_out, self.hidden = self.gru(x, self.hidden)\n","        y = self.hidden2label(gru_out[-1])\n","        return y, gru_out, x"],"execution_count":188,"outputs":[]},{"cell_type":"code","metadata":{"id":"XedF8d3yojDb","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594835206314,"user_tz":300,"elapsed":952,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}}},"source":["class LSTMSentiment(nn.Module):\n","\n","    def __init__(self, embedding_dim, hidden_dim, vocab_size, label_size, use_gpu, batch_size, dropout=0.5):\n","        super(LSTMSentiment, self).__init__()\n","        self.hidden_dim = hidden_dim\n","        self.use_gpu = use_gpu\n","        self.batch_size = batch_size\n","        #self.dropout = dropout\n","        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n","        self.dropout = nn.Dropout(dropout)\n","        self.lstm = nn.LSTM(input_size=embedding_dim, hidden_size=hidden_dim)\n","        self.hidden2label = nn.Linear(hidden_dim, label_size)\n","        self.hidden = self.init_hidden()\n","\n","    def init_hidden(self):\n","        # first is the hidden h\n","        # second is the cell c\n","        if self.use_gpu:\n","            return (Variable(torch.zeros(1, self.batch_size, self.hidden_dim).cuda()),\n","                    Variable(torch.zeros(1, self.batch_size, self.hidden_dim).cuda()))\n","        else:\n","            return (Variable(torch.zeros(1, self.batch_size, self.hidden_dim)),\n","                    Variable(torch.zeros(1, self.batch_size, self.hidden_dim)))\n","\n","    def forward(self, sentence):\n","        x = self.embeddings(sentence).view(len(sentence), self.batch_size, -1)\n","        lstm_out, self.hidden = self.lstm(x, self.hidden)\n","        #lstm_out = self.dropout(lstm_out)\n","        y = self.hidden2label(lstm_out[-1])\n","        return y, lstm_out, x"],"execution_count":189,"outputs":[]},{"cell_type":"code","metadata":{"id":"TEwCBxoGkjui","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594835207484,"user_tz":300,"elapsed":2114,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}},"outputId":"b10e260f-d3f5-47a6-efb3-fdd5b2e730ee"},"source":["!pwd\n"],"execution_count":190,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QGjqyFaBoovV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594835207626,"user_tz":300,"elapsed":2248,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}}},"source":["# import torch\n","# import torch.nn as nn\n","from torchtext import data\n","import numpy as np\n","# from torch.autograd import Variable\n","from nltk.tokenize import word_tokenize\n","# import torch.nn.functional as F\n","\n","\n","\n","def load_sst(text_field, label_field, batch_size):\n","    train, dev, test = data.TabularDataset.splits(path='/content/gdrive/My Drive/twitter misinfo/REATData/', train='train.tsv',\n","                                                  validation='dev.tsv', test='test.tsv', format='tsv',\n","                                                  fields=[('text', text_field), ('label', label_field)])\n","    text_field.build_vocab(train, dev, test)\n","    label_field.build_vocab(train, dev, test)\n","    train_iter, dev_iter, test_iter = data.BucketIterator.splits((train, dev, test),\n","                batch_sizes=(batch_size, len(dev), len(test)), sort_key=lambda x: len(x.text), repeat=False, device=-1) \n","    return train_iter, dev_iter, test_iter\n","\n","def sigmoid(x):\n","    return (1 / (1 + np.exp(-x)))\n","\n","\n","def bigru_attribution(model, text):\n","    # data for word-to-vec\n","    text_field = data.Field(lower=True)  # it is an object\n","    label_field = data.Field(sequential=False)   # it is also an object\n","    train_iter, dev_iter, test_iter = load_sst(text_field, label_field, 5)\n","    # word2vector\n","    word_to_idx = text_field.vocab.stoi  # example of word_to_idx: u'schools': 14512, len(word_to_idx) = 16190\n","    word_to_idx_dict = dict(word_to_idx)\n","\n","    # processing text\n","    word_tokenize_list = word_tokenize(text)\n","    sentence = []\n","    for i in word_tokenize_list:\n","        sentence.append(word_to_idx_dict[i])\n","    sent = np.array(sentence)\n","    sent = Variable(torch.from_numpy(sent))\n","    sent = sent.cuda()\n","    length = len(word_tokenize_list)\n","\n","    # model prediction\n","    best_model.batch_size = 1\n","    best_model.hidden = best_model.init_hidden()\n","    pred, hn, x = best_model(sent)\n","    hn = hn.cpu().data.numpy()\n","    x = x.cpu().data.numpy()\n","    pred = F.softmax(pred).cpu()\n","    pred_label = pred.data.max(1)[1].numpy()\n","    if pred_label[0] == 0:\n","        print (\"prediction category: positive sentiment with confidence of \" + str(pred.data.numpy()[0, 0]))# 0 is positive, and 1 is negative\n","    else:\n","        print (\"prediction category: negative sentiment with confidence of \" + str(pred.data.numpy()[0, 1]))\n","\n","    # attribution for the prediction\n","    weights = best_model.gru.state_dict()\n","\n","    _, W_iz, _ = np.split(weights['weight_ih_l0'].cpu().numpy(), 3, 0)\n","    _, W_hz, _ = np.split(weights['weight_hh_l0'].cpu().numpy(), 3, 0)\n","    _, b_z, _ = np.split(weights['bias_ih_l0'].cpu().numpy() + weights['bias_hh_l0'].cpu().numpy(), 3)\n","\n","    _, W_iz_r, _ = np.split(weights['weight_ih_l0_reverse'].cpu().numpy(), 3, 0)\n","    _, W_hz_r, _ = np.split(weights['weight_hh_l0_reverse'].cpu().numpy(), 3, 0)\n","    _, b_z_r, _ = np.split(weights['bias_ih_l0_reverse'].cpu().numpy() + weights['bias_hh_l0_reverse'].cpu().numpy(), 3)\n","\n","\n","\n","    z_dict = []\n","    z_dict.append(np.ones(150))\n","    for i in range(length-1):\n","        i = i + 1\n","        z = sigmoid(np.matmul(W_iz, x[i,0,:]) + np.matmul(W_hz, hn[i-1,0,:150]) + b_z)\n","        z_dict.append(z)\n","    alpha_dict = z_dict\n","\n","    z_dict_reverse = []\n","    z_dict_reverse.append(np.ones(150))\n","    for i in range(length-1):\n","        i = length - 2 - i\n","        z = sigmoid(np.matmul(W_iz_r, x[i,0,:]) + np.matmul(W_hz_r, hn[i+1,0,150:]) + b_z_r)\n","        z_dict_reverse.append(z)\n","    z_dict_reverse = z_dict_reverse[::-1]\n","    alpha_dict_reverse = z_dict_reverse\n","\n","    weights_linear = best_model.hidden2label.state_dict()\n","    W = weights_linear['weight'].cpu().numpy()\n","    b= weights_linear['bias'].cpu().numpy()\n","\n","    \n","    target_class = pred_label\n","    score_dict = []\n","    for i in range(len(alpha_dict)):\n","        if i == 0:\n","            updating = hn[0,0,:150]\n","        else:\n","            updating = hn[i,0,:150] - alpha_dict[i] * hn[i-1,0,:150]\n","        forgetting = alpha_dict[0]\n","        for j in range(i+1, len(alpha_dict)):\n","            forgetting = forgetting*alpha_dict[j]\n","\n","        if i == len(alpha_dict)-1:\n","            updating_reverse = hn[i,0,150:]\n","        else:\n","            updating_reverse = hn[i,0,150:] - alpha_dict_reverse[i] * hn[i+1,0,150:]\n","        forgetting_reverse = alpha_dict_reverse[-1]\n","        for j in range(i):\n","            forgetting_reverse = forgetting_reverse*alpha_dict_reverse[j]\n","\n","        score = np.matmul( W[target_class], np.concatenate((updating * forgetting,updating_reverse*forgetting_reverse))) #+ b[target_class]\n","        score_dict.append(score[0])\n","\n","    return word_tokenize_list, score_dict"],"execution_count":191,"outputs":[]},{"cell_type":"code","metadata":{"id":"qnjABaItozpu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594835207628,"user_tz":300,"elapsed":2243,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}}},"source":["\n","def load_sst(text_field, label_field, batch_size):\n","    train, dev, test = data.TabularDataset.splits(path='/content/gdrive/My Drive/twitter misinfo/REATData/', train='train.tsv',\n","                                                  validation='dev.tsv', test='test.tsv', format='tsv',\n","                                                  fields=[('text', text_field), ('label', label_field)])\n","    text_field.build_vocab(train, dev, test)\n","    label_field.build_vocab(train, dev, test)\n","    train_iter, dev_iter, test_iter = data.BucketIterator.splits((train, dev, test),\n","                batch_sizes=(batch_size, len(dev), len(test)), sort_key=lambda x: len(x.text), repeat=False, device=-1) \n","    return train_iter, dev_iter, test_iter\n","\n","def sigmoid(x):\n","    return (1 / (1 + np.exp(-x)))\n","\n","\n","\n","def gru_attribution(model, text):\n","    # data for word-to-vec\n","    text_field = data.Field(lower=True)  # it is an object\n","    label_field = data.Field(sequential=False)   # it is also an object\n","    train_iter, dev_iter, test_iter = load_sst(text_field, label_field, 5)\n","    # word2vector\n","    word_to_idx = text_field.vocab.stoi  # example of word_to_idx: u'schools': 14512, len(word_to_idx) = 16190\n","    word_to_idx_dict = dict(word_to_idx)\n","\n","    # processing text\n","    word_tokenize_list = word_tokenize(text)\n","    sentence = []\n","    for i in word_tokenize_list:\n","        sentence.append(word_to_idx_dict[i])\n","    sent = np.array(sentence)\n","    sent = Variable(torch.from_numpy(sent))\n","    sent = sent.cuda()\n","    length = len(word_tokenize_list)\n","\n","    # model prediction\n","    best_model.batch_size = 1\n","    best_model.hidden = best_model.init_hidden()\n","    pred, hn, x = best_model(sent)\n","    hn = hn.cpu().data.numpy()\n","    x = x.cpu().data.numpy()\n","    pred = F.softmax(pred).cpu()\n","    pred_label = pred.data.max(1)[1].numpy()  \n","    if pred_label[0] == 0:\n","        print (\"prediction category: positive sentiment with confidence of \" + str(pred.data.numpy()[0, 0]))# 0 is positive, and 1 is negative\n","    else:\n","        print (\"prediction category: negative sentiment with confidence of \" + str(pred.data.numpy()[0, 1]))\n","\n","\n","    # attribution for the prediction\n","    weights = best_model.gru.state_dict()\n","    _, W_iz, _ = np.split(weights['weight_ih_l0'].cpu().numpy(), 3, 0)\n","    _, W_hz, _ = np.split(weights['weight_hh_l0'].cpu().numpy(), 3, 0)\n","    _, b_z, _ = np.split(weights['bias_ih_l0'].cpu().numpy() + weights['bias_hh_l0'].cpu().numpy(), 3)\n","\n","    z_dict = []\n","    z_dict.append(np.ones(150))\n","    for i in range(length-1):\n","        i = i + 1\n","        z = sigmoid(np.matmul(W_iz, x[i,0,:]) + np.matmul(W_hz, hn[i-1,0,:]) + b_z)\n","        z_dict.append(z)\n","    alpha_dict = z_dict\n","    weights_linear = best_model.hidden2label.state_dict()\n","    W = weights_linear['weight'].cpu().numpy()\n","    b= weights_linear['bias'].cpu().numpy()\n","\n","    target_class = pred_label\n","    score_dict = []\n","    for i in range(len(alpha_dict)):\n","        if i == 0:\n","            updating = hn[0,0,:]\n","        else:\n","            updating = hn[i,0,:] - alpha_dict[i] * hn[i-1,0,:]\n","        forgetting = alpha_dict[0]\n","        for j in range(i+1, len(alpha_dict)):\n","            forgetting = forgetting*alpha_dict[j]\n","        score = np.matmul( W[target_class], updating * forgetting) #+ b[target_class]\n","        score_dict.append(score[0])\n","    return word_tokenize_list, score_dict\n","\n"],"execution_count":192,"outputs":[]},{"cell_type":"code","metadata":{"id":"C5xMTZe9pmCc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594835207824,"user_tz":300,"elapsed":2433,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}}},"source":["\n","def load_sst(text_field, label_field, batch_size):\n","    train, dev, test = data.TabularDataset.splits(path='/content/gdrive/My Drive/twitter misinfo/REATData/', train='train.tsv',\n","                                                  validation='dev.tsv', test='test.tsv', format='tsv',\n","                                                  fields=[('text', text_field), ('label', label_field)])\n","    text_field.build_vocab(train, dev, test)\n","    label_field.build_vocab(train, dev, test)\n","    train_iter, dev_iter, test_iter = data.BucketIterator.splits((train, dev, test),\n","                batch_sizes=(batch_size, len(dev), len(test)), sort_key=lambda x: len(x.text), repeat=False, device=-1) \n","    return train_iter, dev_iter, test_iter\n","\n","def sigmoid(x):\n","    return (1 / (1 + np.exp(-x)))\n","\n","\n","def lstm_attribution(model, text):\n","    # data for word-to-vec\n","    text_field = data.Field(lower=True)  # it is an object\n","    label_field = data.Field(sequential=False)   # it is also an object\n","    train_iter, dev_iter, test_iter = load_sst(text_field, label_field, 5)\n","    # word2vector\n","    word_to_idx = text_field.vocab.stoi  # example of word_to_idx: u'schools': 14512, len(word_to_idx) = 16190\n","    word_to_idx_dict = dict(word_to_idx)\n","\n","    # processing text\n","    word_tokenize_list = word_tokenize(text)\n","    sentence = []\n","    for i in word_tokenize_list:\n","        sentence.append(word_to_idx_dict[i])\n","    sent = np.array(sentence)\n","    sent = Variable(torch.from_numpy(sent))\n","    sent = sent.cuda()\n","    length = len(word_tokenize_list)\n","\n","    # model prediction\n","    best_model.batch_size = 1\n","    best_model.hidden = best_model.init_hidden()\n","    pred, hn, x = best_model(sent)\n","    hn = hn.cpu().data.numpy()\n","    x = x.cpu().data.numpy()\n","    pred = F.softmax(pred).cpu()\n","    pred_label = pred.data.max(1)[1].numpy()  \n","    if pred_label[0] == 0:\n","        print (\"prediction category: positive sentiment with confidence of \" + str(pred.data.numpy()[0, 0]))# 0 is positive, and 1 is negative\n","    else:\n","        print (\"prediction category: negative sentiment with confidence of \" + str(pred.data.numpy()[0, 1]))\n","\n","    # attribution for the prediction\n","    weights = best_model.lstm.state_dict()\n","    W_ii, W_if, W_ig, W_io = np.split(weights['weight_ih_l0'].cpu().numpy(), 4, 0)\n","    W_hi, W_hf, W_hg, W_ho = np.split(weights['weight_hh_l0'].cpu().numpy(), 4, 0)\n","    b_i, b_f, b_g, b_o = np.split(weights['bias_ih_l0'].cpu().numpy() + weights['bias_hh_l0'].cpu().numpy(), 4)\n","\n","\n","    z_dict = []\n","    z_dict.append(np.ones(150))\n","    for i in range(length-1):\n","        i = i + 1\n","        z = sigmoid(np.matmul(W_if, x[i,0,:]) + np.matmul(W_hf, hn[i-1,0,:]) + b_f)\n","        z_dict.append(z)\n","\n","    o_dict = []\n","    for i in range(length):\n","        if i == 0:\n","            o = sigmoid(np.matmul(W_io, x[i,0,:]) + b_o)\n","        else:\n","            o = sigmoid(np.matmul(W_io, x[i,0,:]) + np.matmul(W_ho, hn[i-1,0,:]) + b_o)\n","        o_dict.append(o)\n","\n","\n","    alpha_dict = []\n","    for i in range(len(z_dict)):\n","        if i == 0:\n","            alpha_dict.append(z_dict[0])\n","        else:\n","            alpha_dict.append(z_dict[i] * o_dict[i] / o_dict[i-1])\n","\n","    weights_linear = best_model.hidden2label.state_dict()\n","    W = weights_linear['weight'].cpu().numpy()\n","    b= weights_linear['bias'].cpu().numpy()\n","    target_class = pred_label\n","\n","\n","    score_dict = []\n","    for i in range(len(alpha_dict)):\n","        if i == 0:\n","            updating = hn[0,0,:]\n","        else:\n","            updating = hn[i,0,:] - alpha_dict[i] * hn[i-1,0,:]\n","        forgetting = alpha_dict[0]\n","        for j in range(i+1, len(alpha_dict)):\n","            forgetting = forgetting*alpha_dict[j]\n","        score = np.matmul( W[target_class], updating * forgetting) \n","        score_dict.append(score[0])\n","    return word_tokenize_list, score_dict"],"execution_count":193,"outputs":[]},{"cell_type":"code","metadata":{"id":"grRfw1R3ptuA","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594835208208,"user_tz":300,"elapsed":2813,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}}},"source":["# import torch\n","# import torch.nn as nn\n","from torch import optim\n","import time, random\n","import os\n","from tqdm import tqdm\n","# from lstm import LSTMSentiment\n","# from gru import GRUSentiment\n","# from bigru import BiGRUSentiment\n","from torchtext import data\n","import numpy as np\n","import argparse\n","# from torch.autograd import Variable\n","# import torch.nn.functional as F\n","\n","torch.set_num_threads(8)\n","torch.manual_seed(1)\n","random.seed(1)\n","\n","\n","def load_bin_vec(fname, vocab):\n","    \"\"\"\n","    Loads 300x1 word vecs from Google (Mikolov) word2vec\n","    \"\"\"\n","    word_vecs = {}\n","    with open(fname, \"rb\") as f:\n","        header = f.readline()\n","        vocab_size, layer1_size = map(int, header.split())\n","        binary_len = np.dtype('float32').itemsize * layer1_size\n","        for line in range(vocab_size):\n","            word = []\n","            while True:\n","                ch = f.read(1).decode('latin-1')\n","                if ch == ' ':\n","                    word = ''.join(word)\n","                    break\n","                if ch != '\\n':\n","                    word.append(ch)\n","            if word in vocab:\n","               word_vecs[word] = np.fromstring(f.read(binary_len), dtype='float32')\n","            else:\n","                f.read(binary_len)\n","    return word_vecs\n","\n","\n","def get_accuracy(truth, pred):\n","    assert len(truth) == len(pred)\n","    right = 0\n","    for i in range(len(truth)):\n","        if truth[i] == pred[i]:\n","            right += 1.0\n","    return right / len(truth)\n","\n","\n","def train_epoch_progress(model, train_iter, loss_function, optimizer, text_field, label_field, epoch):\n","    model.train()\n","    avg_loss = 0.0\n","    truth_res = []\n","    pred_res = []\n","    count = 0\n","    for batch in tqdm(train_iter, desc='Train epoch '+str(epoch+1)):\n","        sent, label = batch.text, batch.label\n","        label.data.sub_(1)\n","        truth_res += list(label.data)\n","        model.batch_size = len(label.data)\n","        model.hidden = model.init_hidden()\n","        sent = sent.cuda()\n","        pred, _, _ = model(sent)\n","        pred = F.log_softmax(pred)\n","        pred = pred.cpu()\n","        pred_label = pred.data.max(1)[1].numpy()\n","        pred_res += [x for x in pred_label]\n","        model.zero_grad()\n","        loss = loss_function(pred, label)\n","        # avg_loss += loss.data[0]\n","        avg_loss += loss.data\n","        count += 1\n","        loss.backward()\n","        optimizer.step()\n","    avg_loss /= len(train_iter)\n","    acc = get_accuracy(truth_res, pred_res)\n","    return avg_loss, acc\n","\n","\n","def evaluate(model, data, loss_function, name):\n","    model.eval()\n","    avg_loss = 0.0\n","    truth_res = []\n","    pred_res = []\n","    for batch in data:\n","        sent, label = batch.text, batch.label\n","        label.data.sub_(1)\n","        truth_res += list(label.data)\n","        model.batch_size = len(label.data)\n","        model.hidden = model.init_hidden()\n","        sent = sent.cuda()\n","        pred, _, _ = model(sent)\n","        pred = F.log_softmax(pred)\n","        pred = pred.cpu()\n","        pred_label = pred.data.max(1)[1].numpy()\n","        pred_res += [x for x in pred_label]\n","        loss = loss_function(pred, label)\n","        # avg_loss += loss.data[0]\n","        avg_loss += loss.data\n","    avg_loss /= len(data)\n","    acc = get_accuracy(truth_res, pred_res)\n","    print(name + ': loss %.2f acc %.1f' % (avg_loss, acc*100))\n","    return acc\n","\n","\n","def load_sst(text_field, label_field, batch_size):\n","    train, dev, test = data.TabularDataset.splits(path='/content/gdrive/My Drive/twitter misinfo/REATData/', train='train.tsv',\n","                                                  validation='dev.tsv', test='test.tsv', format='tsv',\n","                                                  fields=[('text', text_field), ('label', label_field)])\n","    text_field.build_vocab(train, dev, test)\n","    label_field.build_vocab(train, dev, test)\n","    train_iter, dev_iter, test_iter = data.BucketIterator.splits((train, dev, test),\n","                batch_sizes=(batch_size, len(dev), len(test)), sort_key=lambda x: len(x.text), repeat=False, device=-1)\n","    ## for GPU run\n","#     train_iter, dev_iter, test_iter = data.BucketIterator.splits((train, dev, test),\n","#                 batch_sizes=(batch_size, len(dev), len(test)), sort_key=lambda x: len(x.text), repeat=False, device=None)\n","    return train_iter, dev_iter, test_iter\n","\n","\n","\n","# args = argparse.ArgumentParser()\n","# args.add_argument('--m', dest='model', default='lstm', help='specify the mode to use (default: lstm)')\n","# args = args.parse_args()\n","\n","def runModel( modelName='lstm'):\n","    EPOCHS = 20\n","    USE_GPU = torch.cuda.is_available()\n","    EMBEDDING_DIM = 300\n","    HIDDEN_DIM = 150\n","\n","    BATCH_SIZE = 5\n","    timestamp = str(int(time.time()))\n","    best_dev_acc = 0.0\n","\n","\n","    # data is from torchtext.data, it is an object\n","    text_field = data.Field(lower=True)\n","    label_field = data.Field(sequential=False)\n","    train_iter, dev_iter, test_iter = load_sst(text_field, label_field, BATCH_SIZE)\n","    print(text_field, label_field)\n","\n","\n","    if modelName == 'lstm':\n","        print('model is lstm')\n","        model = LSTMSentiment(embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, vocab_size=len(text_field.vocab), label_size=len(label_field.vocab)-1,\\\n","                            use_gpu=USE_GPU, batch_size=BATCH_SIZE)\n","\n","    if modelName == 'gru':\n","        print('model is gru')\n","        model = GRUSentiment(embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, vocab_size=len(text_field.vocab), label_size=len(label_field.vocab)-1,\\\n","                            use_gpu=USE_GPU, batch_size=BATCH_SIZE)\n","\n","    if modelName == 'bigru':\n","        print('model is bigru')\n","        model = BiGRUSentiment(embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, vocab_size=len(text_field.vocab), label_size=len(label_field.vocab)-1,\\\n","                            use_gpu=USE_GPU, batch_size=BATCH_SIZE)\n","\n","    if USE_GPU:\n","        print('use cuda')\n","        model = model.cuda()\n","        # .deatch().cpu().clone().numpy()\n","\n","\n","    print('Load word embeddings...')\n","    # word2vector\n","    word_to_idx = text_field.vocab.stoi\n","    # example of word_to_idx: u'schools': 14512, u'mimicking': 12930\n","    # len(word_to_idx) = 16190\n","    pretrained_embeddings = np.random.uniform(-0.25, 0.25, (len(text_field.vocab), 300))\n","    # pretrained_embeddings.shape = (16190, 300)\n","\n","    pretrained_embeddings[0] = 0 #set all pretrained_embeddings[0] to 0\n","    word2vec = load_bin_vec('/content/gdrive/My Drive/twitter misinfo/news_vec/GoogleNews-vectors-negative300.bin', word_to_idx)\n","    for word, vector in word2vec.items():\n","        pretrained_embeddings[word_to_idx[word]-1] = vector\n","    # the embedding layer of this model is using the pretrained embeddings\n","    model.embeddings.weight.data.copy_(torch.from_numpy(pretrained_embeddings))\n","    # model.embeddings.weight.data = text_field.vocab.vectors\n","    # model.embeddings.embed.weight.requires_grad = False\n","\n","\n","    best_model = model\n","    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","    loss_function = nn.NLLLoss()\n","\n","\n","    print('Training...')\n","    if modelName == 'gru':\n","        out_dir = \"models/gru\"\n","    elif modelName == 'lstm':\n","        out_dir = \"models/lstm\"\n","    else:\n","        out_dir = \"models/bigru\"\n","\n","    #out_dir = os.path.abspath(os.path.join(os.path.curdir, \"runs\", timestamp))\n","    print(\"Writing to {}\\n\".format(out_dir))\n","    if not os.path.exists(out_dir):\n","        os.makedirs(out_dir)\n","    for epoch in range(EPOCHS):\n","        avg_loss, acc = train_epoch_progress(model, train_iter, loss_function, optimizer, text_field, label_field, epoch)\n","        tqdm.write('Train: loss %.2f acc %.1f' % (avg_loss, acc*100))\n","        dev_acc = evaluate(model, dev_iter, loss_function, 'Dev')\n","        if dev_acc > best_dev_acc:\n","            if best_dev_acc > 0:\n","                os.system('rm '+ out_dir + '/best_model' + '.pkl')\n","            best_dev_acc = dev_acc\n","            best_model = model\n","            torch.save(best_model, out_dir + '/best_model' + '.pkl')\n","            # evaluate on test with the best dev performance model\n","            test_acc = evaluate(best_model, test_iter, loss_function, 'Test')\n","\n","\n","    return test_iter, loss_function"],"execution_count":194,"outputs":[]},{"cell_type":"code","metadata":{"id":"1gKqj2g-EVyZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594835208210,"user_tz":300,"elapsed":2810,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}}},"source":["# !wget https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit"],"execution_count":195,"outputs":[]},{"cell_type":"code","metadata":{"id":"A-TP0ITNTXUV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594835208211,"user_tz":300,"elapsed":2804,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}}},"source":["# !wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\""],"execution_count":196,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kc4pc4BrVAeD","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594835208212,"user_tz":300,"elapsed":2800,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}}},"source":["# import zipfile\n","\n","\n","# zip_ref = zipfile.ZipFile(\"/content/GoogleNews-vectors-negative300.bin.gz\", 'r')\n","# zip_ref.extractall(\"/content/gdrive/My Drive/twitter misinfo/REATData/\")\n","# zip_ref.close()\n","\n","# !tar -xvf  '/content/GoogleNews-vectors-negative300.bin.gz' -C '/content/gdrive/My Drive/twitter misinfo/REATData/'"],"execution_count":197,"outputs":[]},{"cell_type":"code","metadata":{"id":"DM84Uve0Tkbl","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594835208214,"user_tz":300,"elapsed":2797,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}}},"source":["# !unzip '/content/GoogleNews-vectors-negative300.bin.gz' -d '/content/gdrive/My Drive/twitter misinfo/REATData/'"],"execution_count":198,"outputs":[]},{"cell_type":"code","metadata":{"id":"wntJULfQXZO0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594835208214,"user_tz":300,"elapsed":2793,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}}},"source":["# !gunzip '/content/GoogleNews-vectors-negative300.bin.gz'"],"execution_count":199,"outputs":[]},{"cell_type":"code","metadata":{"id":"WVsiF_q-YqIw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1594835209244,"user_tz":300,"elapsed":3818,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}},"outputId":"a9cc00a8-9d9a-4ffd-b184-126b3932ce26"},"source":["!mv '/content/GoogleNews-vectors-negative300.bin' '/content/gdrive/My Drive/twitter misinfo/news_vec/'"],"execution_count":200,"outputs":[{"output_type":"stream","text":["mv: cannot stat '/content/GoogleNews-vectors-negative300.bin': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XcJcHLrACk3_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594835329422,"user_tz":300,"elapsed":123989,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}},"outputId":"48299fc7-28f2-4a5f-d208-46145716903d"},"source":["model_name = 'lstm'\n","\n","if model_name == 'gru':\n","    out_dir = \"models/gru\"\n","elif model_name == 'lstm':\n","    out_dir = \"models/lstm\"\n","else:\n","    out_dir = \"models/bigru\"\n","\n","test_iter, loss_function = runModel(modelName = model_name)\n","\n","\n","best_model = torch.load(out_dir + '/best_model' + '.pkl')\n","test_acc = evaluate(best_model, test_iter, loss_function, 'Final Test')"],"execution_count":201,"outputs":[{"output_type":"stream","text":["The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n","The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n","The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"],"name":"stderr"},{"output_type":"stream","text":["<torchtext.data.field.Field object at 0x7fe04113c588> <torchtext.data.field.Field object at 0x7fe04113cd68>\n","model is lstm\n","use cuda\n","Load word embeddings...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n","Train epoch 1:   0%|          | 0/1384 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","Train epoch 1:   2%|▏         | 26/1384 [00:00<00:05, 259.77it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training...\n","Writing to models/lstm\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 1: 100%|██████████| 1384/1384 [00:04<00:00, 292.07it/s]\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:98: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type LSTMSentiment. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","Train epoch 2:   0%|          | 0/1384 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.69 acc 51.5\n","Dev: loss 0.69 acc 50.9\n","Test: loss 0.69 acc 49.9\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 2: 100%|██████████| 1384/1384 [00:04<00:00, 285.70it/s]\n","Train epoch 3:   0%|          | 0/1384 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.61 acc 65.9\n","Dev: loss 0.51 acc 74.8\n","Test: loss 0.51 acc 76.9\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 3: 100%|██████████| 1384/1384 [00:04<00:00, 289.07it/s]\n","Train epoch 4:   0%|          | 0/1384 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.28 acc 88.6\n","Dev: loss 0.48 acc 77.8\n","Test: loss 0.45 acc 78.8\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 4: 100%|██████████| 1384/1384 [00:04<00:00, 289.59it/s]\n","Train epoch 5:   2%|▏         | 26/1384 [00:00<00:05, 252.36it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.10 acc 96.4\n","Dev: loss 0.70 acc 75.3\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 5: 100%|██████████| 1384/1384 [00:04<00:00, 292.05it/s]\n","Train epoch 6:   2%|▏         | 28/1384 [00:00<00:04, 277.12it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.04 acc 98.8\n","Dev: loss 0.83 acc 77.5\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 6: 100%|██████████| 1384/1384 [00:04<00:00, 293.36it/s]\n","Train epoch 7:   2%|▏         | 29/1384 [00:00<00:04, 284.17it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.02 acc 99.5\n","Dev: loss 1.11 acc 77.2\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 7: 100%|██████████| 1384/1384 [00:04<00:00, 291.53it/s]\n","Train epoch 8:   0%|          | 0/1384 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.01 acc 99.7\n","Dev: loss 1.40 acc 78.1\n","Test: loss 1.26 acc 78.4\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 8: 100%|██████████| 1384/1384 [00:04<00:00, 289.86it/s]\n","Train epoch 9:   0%|          | 0/1384 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 99.9\n","Dev: loss 1.50 acc 78.2\n","Test: loss 1.38 acc 79.0\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 9: 100%|██████████| 1384/1384 [00:04<00:00, 290.67it/s]\n","Train epoch 10:   2%|▏         | 29/1384 [00:00<00:04, 282.39it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 99.9\n","Dev: loss 1.74 acc 77.2\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 10: 100%|██████████| 1384/1384 [00:04<00:00, 289.01it/s]\n","Train epoch 11:   2%|▏         | 27/1384 [00:00<00:05, 263.71it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 1.98 acc 78.1\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 11: 100%|██████████| 1384/1384 [00:04<00:00, 289.56it/s]\n","Train epoch 12:   2%|▏         | 28/1384 [00:00<00:04, 272.42it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 2.23 acc 77.8\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 12: 100%|██████████| 1384/1384 [00:04<00:00, 288.91it/s]\n","Train epoch 13:   2%|▏         | 28/1384 [00:00<00:04, 278.19it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 2.42 acc 77.4\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 13: 100%|██████████| 1384/1384 [00:04<00:00, 289.69it/s]\n","Train epoch 14:   2%|▏         | 23/1384 [00:00<00:05, 227.80it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 2.55 acc 77.8\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 14: 100%|██████████| 1384/1384 [00:04<00:00, 290.02it/s]\n","Train epoch 15:   2%|▏         | 29/1384 [00:00<00:04, 280.62it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 2.82 acc 77.4\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 15: 100%|██████████| 1384/1384 [00:04<00:00, 291.69it/s]\n","Train epoch 16:   2%|▏         | 28/1384 [00:00<00:04, 274.31it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 3.06 acc 76.3\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 16: 100%|██████████| 1384/1384 [00:04<00:00, 289.80it/s]\n","Train epoch 17:   0%|          | 0/1384 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.01 acc 99.7\n","Dev: loss 1.46 acc 79.4\n","Test: loss 1.37 acc 78.2\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 17: 100%|██████████| 1384/1384 [00:04<00:00, 287.61it/s]\n","Train epoch 18:   2%|▏         | 25/1384 [00:00<00:05, 246.44it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.01 acc 99.7\n","Dev: loss 1.38 acc 77.4\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 18: 100%|██████████| 1384/1384 [00:04<00:00, 281.73it/s]\n","Train epoch 19:   2%|▏         | 29/1384 [00:00<00:04, 281.68it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 1.75 acc 76.6\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 19: 100%|██████████| 1384/1384 [00:04<00:00, 288.24it/s]\n","Train epoch 20:   2%|▏         | 28/1384 [00:00<00:05, 270.30it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 1.95 acc 77.1\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 20: 100%|██████████| 1384/1384 [00:04<00:00, 283.08it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 2.13 acc 77.4\n","Final Test: loss 1.37 acc 78.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zAubvpzQTNQl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594835449410,"user_tz":300,"elapsed":243970,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}},"outputId":"70227f07-aab7-4dae-a787-b0975ed5566e"},"source":["model_name = 'gru'\n","\n","if model_name == 'gru':\n","    out_dir = \"models/gru\"\n","elif model_name == 'lstm':\n","    out_dir = \"models/lstm\"\n","else:\n","    out_dir = \"models/bigru\"\n","\n","test_iter, loss_function = runModel(modelName = model_name)\n","\n","\n","best_model = torch.load(out_dir + '/best_model' + '.pkl')\n","test_acc = evaluate(best_model, test_iter, loss_function, 'Final Test')"],"execution_count":202,"outputs":[{"output_type":"stream","text":["The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n","The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n","The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"],"name":"stderr"},{"output_type":"stream","text":["<torchtext.data.field.Field object at 0x7fe0729f1358> <torchtext.data.field.Field object at 0x7fe0729f1048>\n","model is gru\n","use cuda\n","Load word embeddings...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n","Train epoch 1:   0%|          | 0/1384 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","Train epoch 1:   2%|▏         | 27/1384 [00:00<00:05, 262.87it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training...\n","Writing to models/gru\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 1: 100%|██████████| 1384/1384 [00:04<00:00, 291.87it/s]\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:98: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type GRUSentiment. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","Train epoch 2:   0%|          | 0/1384 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.69 acc 51.3\n","Dev: loss 0.69 acc 50.9\n","Test: loss 0.69 acc 49.9\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 2: 100%|██████████| 1384/1384 [00:04<00:00, 290.81it/s]\n","Train epoch 3:   0%|          | 0/1384 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.53 acc 72.2\n","Dev: loss 0.43 acc 80.3\n","Test: loss 0.42 acc 81.2\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 3: 100%|██████████| 1384/1384 [00:04<00:00, 292.40it/s]\n","Train epoch 4:   0%|          | 0/1384 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.19 acc 92.8\n","Dev: loss 0.46 acc 81.2\n","Test: loss 0.45 acc 81.1\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 4: 100%|██████████| 1384/1384 [00:04<00:00, 291.33it/s]\n","Train epoch 5:   2%|▏         | 28/1384 [00:00<00:04, 274.78it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.05 acc 98.6\n","Dev: loss 0.83 acc 79.4\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 5: 100%|██████████| 1384/1384 [00:04<00:00, 293.29it/s]\n","Train epoch 6:   2%|▏         | 27/1384 [00:00<00:05, 265.28it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.02 acc 99.6\n","Dev: loss 0.94 acc 79.5\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 6: 100%|██████████| 1384/1384 [00:04<00:00, 291.81it/s]\n","Train epoch 7:   2%|▏         | 28/1384 [00:00<00:04, 273.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.01 acc 99.7\n","Dev: loss 1.22 acc 78.7\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 7: 100%|██████████| 1384/1384 [00:04<00:00, 291.57it/s]\n","Train epoch 8:   2%|▏         | 27/1384 [00:00<00:05, 267.03it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 99.8\n","Dev: loss 1.32 acc 78.4\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 8: 100%|██████████| 1384/1384 [00:04<00:00, 288.79it/s]\n","Train epoch 9:   2%|▏         | 28/1384 [00:00<00:04, 277.35it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 1.57 acc 77.1\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 9: 100%|██████████| 1384/1384 [00:04<00:00, 290.36it/s]\n","Train epoch 10:   2%|▏         | 30/1384 [00:00<00:04, 292.81it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 1.61 acc 78.2\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 10: 100%|██████████| 1384/1384 [00:04<00:00, 292.70it/s]\n","Train epoch 11:   2%|▏         | 28/1384 [00:00<00:04, 275.68it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 99.9\n","Dev: loss 1.52 acc 77.3\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 11: 100%|██████████| 1384/1384 [00:04<00:00, 288.36it/s]\n","Train epoch 12:   2%|▏         | 28/1384 [00:00<00:04, 275.73it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.01 acc 99.8\n","Dev: loss 1.56 acc 77.4\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 12: 100%|██████████| 1384/1384 [00:04<00:00, 289.18it/s]\n","Train epoch 13:   2%|▏         | 27/1384 [00:00<00:05, 263.23it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 99.9\n","Dev: loss 1.61 acc 76.6\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 13: 100%|██████████| 1384/1384 [00:04<00:00, 292.62it/s]\n","Train epoch 14:   2%|▏         | 27/1384 [00:00<00:05, 262.82it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 1.79 acc 75.1\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 14: 100%|██████████| 1384/1384 [00:04<00:00, 291.24it/s]\n","Train epoch 15:   2%|▏         | 28/1384 [00:00<00:04, 276.31it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 1.64 acc 77.6\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 15: 100%|██████████| 1384/1384 [00:05<00:00, 275.35it/s]\n","Train epoch 16:   2%|▏         | 27/1384 [00:00<00:05, 267.70it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 1.74 acc 77.4\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 16: 100%|██████████| 1384/1384 [00:05<00:00, 267.84it/s]\n","Train epoch 17:   2%|▏         | 25/1384 [00:00<00:05, 245.78it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 1.78 acc 77.3\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 17: 100%|██████████| 1384/1384 [00:04<00:00, 289.52it/s]\n","Train epoch 18:   2%|▏         | 29/1384 [00:00<00:04, 285.58it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 1.85 acc 77.4\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 18: 100%|██████████| 1384/1384 [00:04<00:00, 291.89it/s]\n","Train epoch 19:   2%|▏         | 27/1384 [00:00<00:05, 268.26it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 1.93 acc 77.3\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 19: 100%|██████████| 1384/1384 [00:04<00:00, 292.13it/s]\n","Train epoch 20:   2%|▏         | 27/1384 [00:00<00:05, 260.55it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 2.01 acc 77.4\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 20: 100%|██████████| 1384/1384 [00:04<00:00, 290.80it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 2.09 acc 77.5\n","Final Test: loss 0.45 acc 81.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H3k7ka8ATNek","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594835605462,"user_tz":300,"elapsed":400013,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}},"outputId":"e68e8b8d-0111-4de4-f3fa-1daac418b4d2"},"source":["model_name = 'bigru'\n","\n","if model_name == 'gru':\n","    out_dir = \"models/gru\"\n","elif model_name == 'lstm':\n","    out_dir = \"models/lstm\"\n","else:\n","    out_dir = \"models/bigru\"\n","\n","test_iter, loss_function = runModel(modelName = model_name)\n","\n","\n","best_model = torch.load(out_dir + '/best_model' + '.pkl')\n","test_acc = evaluate(best_model, test_iter, loss_function, 'Final Test')"],"execution_count":203,"outputs":[{"output_type":"stream","text":["The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n","The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n","The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"],"name":"stderr"},{"output_type":"stream","text":["<torchtext.data.field.Field object at 0x7fe072202c50> <torchtext.data.field.Field object at 0x7fe139823c88>\n","model is bigru\n","use cuda\n","Load word embeddings...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n","Train epoch 1:   0%|          | 0/1384 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","Train epoch 1:   1%|▏         | 20/1384 [00:00<00:07, 191.59it/s]"],"name":"stderr"},{"output_type":"stream","text":["Training...\n","Writing to models/bigru\n","\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 1: 100%|██████████| 1384/1384 [00:06<00:00, 209.23it/s]\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:98: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type BiGRUSentiment. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n","Train epoch 2:   0%|          | 0/1384 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.58 acc 66.9\n","Dev: loss 0.47 acc 77.8\n","Test: loss 0.44 acc 80.0\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 2: 100%|██████████| 1384/1384 [00:06<00:00, 206.55it/s]\n","Train epoch 3:   0%|          | 0/1384 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.26 acc 89.2\n","Dev: loss 0.47 acc 80.0\n","Test: loss 0.43 acc 81.8\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 3: 100%|██████████| 1384/1384 [00:06<00:00, 206.66it/s]\n","Train epoch 4:   1%|▏         | 20/1384 [00:00<00:06, 199.88it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.06 acc 98.2\n","Dev: loss 0.67 acc 78.1\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 4: 100%|██████████| 1384/1384 [00:06<00:00, 210.09it/s]\n","Train epoch 5:   1%|▏         | 20/1384 [00:00<00:07, 193.50it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.02 acc 99.4\n","Dev: loss 0.97 acc 77.1\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 5: 100%|██████████| 1384/1384 [00:06<00:00, 212.98it/s]\n","Train epoch 6:   2%|▏         | 21/1384 [00:00<00:06, 204.96it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.01 acc 99.8\n","Dev: loss 1.00 acc 77.5\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 6: 100%|██████████| 1384/1384 [00:06<00:00, 210.08it/s]\n","Train epoch 7:   1%|▏         | 20/1384 [00:00<00:07, 190.31it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.01 acc 99.8\n","Dev: loss 1.18 acc 75.6\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 7: 100%|██████████| 1384/1384 [00:06<00:00, 210.48it/s]\n","Train epoch 8:   1%|▏         | 20/1384 [00:00<00:06, 199.86it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.01 acc 99.8\n","Dev: loss 1.24 acc 76.6\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 8: 100%|██████████| 1384/1384 [00:06<00:00, 209.61it/s]\n","Train epoch 9:   1%|          | 17/1384 [00:00<00:08, 167.73it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.01 acc 99.8\n","Dev: loss 1.36 acc 75.1\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 9: 100%|██████████| 1384/1384 [00:06<00:00, 208.44it/s]\n","Train epoch 10:   2%|▏         | 21/1384 [00:00<00:06, 209.99it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 99.9\n","Dev: loss 1.66 acc 77.4\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 10: 100%|██████████| 1384/1384 [00:06<00:00, 210.04it/s]\n","Train epoch 11:   1%|▏         | 19/1384 [00:00<00:07, 189.58it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 1.73 acc 77.4\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 11: 100%|██████████| 1384/1384 [00:06<00:00, 210.80it/s]\n","Train epoch 12:   1%|▏         | 19/1384 [00:00<00:07, 188.58it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 1.82 acc 76.6\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 12: 100%|██████████| 1384/1384 [00:06<00:00, 207.70it/s]\n","Train epoch 13:   2%|▏         | 21/1384 [00:00<00:06, 208.10it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 1.87 acc 76.6\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 13: 100%|██████████| 1384/1384 [00:06<00:00, 212.83it/s]\n","Train epoch 14:   2%|▏         | 21/1384 [00:00<00:06, 205.96it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 1.91 acc 76.6\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 14: 100%|██████████| 1384/1384 [00:06<00:00, 208.66it/s]\n","Train epoch 15:   1%|▏         | 20/1384 [00:00<00:07, 193.82it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 2.14 acc 76.7\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 15: 100%|██████████| 1384/1384 [00:06<00:00, 207.21it/s]\n","Train epoch 16:   1%|▏         | 19/1384 [00:00<00:07, 183.23it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 99.9\n","Dev: loss 2.46 acc 71.2\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 16: 100%|██████████| 1384/1384 [00:06<00:00, 208.37it/s]\n","Train epoch 17:   2%|▏         | 21/1384 [00:00<00:06, 208.52it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.01 acc 99.6\n","Dev: loss 2.10 acc 76.3\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 17: 100%|██████████| 1384/1384 [00:06<00:00, 210.38it/s]\n","Train epoch 18:   1%|▏         | 20/1384 [00:00<00:06, 197.30it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 99.9\n","Dev: loss 2.00 acc 75.1\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 18: 100%|██████████| 1384/1384 [00:06<00:00, 209.90it/s]\n","Train epoch 19:   1%|▏         | 20/1384 [00:00<00:06, 199.34it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 99.9\n","Dev: loss 2.12 acc 74.9\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 19: 100%|██████████| 1384/1384 [00:06<00:00, 210.26it/s]\n","Train epoch 20:   2%|▏         | 21/1384 [00:00<00:06, 202.93it/s]"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 2.30 acc 75.2\n"],"name":"stdout"},{"output_type":"stream","text":["Train epoch 20: 100%|██████████| 1384/1384 [00:06<00:00, 208.29it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Train: loss 0.00 acc 100.0\n","Dev: loss 2.30 acc 74.5\n","Final Test: loss 0.43 acc 81.8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k7H_LBjGpgdD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":274},"executionInfo":{"status":"ok","timestamp":1594835605762,"user_tz":300,"elapsed":400307,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}},"outputId":"f2691025-f37d-43ca-9aff-d9ee64907b95"},"source":["# testing text REAT GRU\n","text = \"the fight scenes are fun but it grows tedious\"\n","# text = \"the story may be new, but it does not serve lots of laughs\"\n","best_model = torch.load('models/gru/best_model.pkl')\n","word_tokenize_list, score_dict = gru_attribution(best_model, text) \n","\n","\n","for i in range(len(score_dict)):\n","    print(word_tokenize_list[i], score_dict[i])"],"execution_count":204,"outputs":[{"output_type":"stream","text":["The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n","The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n","The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"],"name":"stderr"},{"output_type":"stream","text":["prediction category: positive sentiment with confidence of 0.5652975\n","the -0.0012669097229697055\n","fight 0.02889450546675601\n","scenes 0.012092458623083564\n","are -0.002933762114131487\n","fun 0.7640238165652878\n","but 0.03971543003468291\n","it 0.05716578755473795\n","grows -0.037601178074776996\n","tedious -0.6784781642950917\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:42: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0EhlUZr2z-RD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1594835605765,"user_tz":300,"elapsed":400302,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}},"outputId":"6bb23777-49cd-490a-f86d-14c14f85ae9f"},"source":["import nltk\n","\n","nltk.download('punkt')"],"execution_count":205,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":205}]},{"cell_type":"code","metadata":{"id":"0U49FufaE-mS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":109},"executionInfo":{"status":"ok","timestamp":1594835605767,"user_tz":300,"elapsed":400296,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}},"outputId":"946c5c46-891d-4f1a-f3bc-e04d17b6ea8b"},"source":["best_model"],"execution_count":206,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GRUSentiment(\n","  (embeddings): Embedding(16190, 300)\n","  (gru): GRU(300, 150)\n","  (hidden2label): Linear(in_features=150, out_features=2, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":206}]},{"cell_type":"code","metadata":{"id":"rgi3tx3YJevu","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594835605768,"user_tz":300,"elapsed":400291,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}}},"source":["# device = torch.device('cpu')"],"execution_count":207,"outputs":[]},{"cell_type":"code","metadata":{"id":"rc2s9d7lprNa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":274},"executionInfo":{"status":"ok","timestamp":1594835606261,"user_tz":300,"elapsed":400779,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}},"outputId":"7028a64e-27a3-4282-c1db-ba17e6bcc55c"},"source":["# testing text REAT LSTM\n","text = \"the fight scenes are fun but it grows tedious\"\n","# text = \"the story may be new, but it does not serve lots of laughs\"\n","best_model = torch.load('models/lstm/best_model.pkl')\n","word_tokenize_list, score_dict = lstm_attribution(best_model, text)\n","\n","\n","for i in range(len(score_dict)):\n","    print(word_tokenize_list[i], score_dict[i])"],"execution_count":208,"outputs":[{"output_type":"stream","text":["The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n","The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n","The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"],"name":"stderr"},{"output_type":"stream","text":["prediction category: positive sentiment with confidence of 0.9998524\n","the 0.00822999503301368\n","fight 1.6702979925432175\n","scenes -0.12405586189557385\n","are 0.058003913862864104\n","fun 1.4125126823478495\n","but 0.3106269395908062\n","it 0.20171123215519676\n","grows 0.8320851439000221\n","tedious 0.012343473319678064\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9ERTyLZspOyN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":274},"executionInfo":{"status":"ok","timestamp":1594835606416,"user_tz":300,"elapsed":400927,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}},"outputId":"090dd702-81b5-4d2c-ed27-743ca581485f"},"source":["# testing text REAT BiGRU\n","text = \"the fight scenes are fun but it grows tedious\"\n","#text = \"the story may be new, but it does not serve lots of laughs\"\n","best_model = torch.load('models/bigru/best_model.pkl')\n","\n","word_tokenize_list, score_dict = bigru_attribution(best_model, text) \n","\n","\n","for i in range(len(score_dict)):\n","    print(word_tokenize_list[i], score_dict[i])"],"execution_count":209,"outputs":[{"output_type":"stream","text":["The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n","The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n","The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"],"name":"stderr"},{"output_type":"stream","text":["prediction category: negative sentiment with confidence of 0.7518371\n","the 0.04165439800714155\n","fight -0.043117512648348524\n","scenes 0.005040971845929512\n","are -0.06339623710076298\n","fun -0.3209914180062183\n","but 0.06472793711242318\n","it -0.00028146558467827823\n","grows 0.34954928924486167\n","tedious 0.3983019658129142\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Po9b7ajYqO9m","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594835606419,"user_tz":300,"elapsed":400924,"user":{"displayName":"Mukund Srinath Heragu","photoUrl":"","userId":"03076730854199538823"}}},"source":[""],"execution_count":209,"outputs":[]}]}